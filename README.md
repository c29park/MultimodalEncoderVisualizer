# MultimodalEncoderVisualizer
## Aim
Given a video with multiple speakers, we perform automatic speech recognition as well as speaker diarization. We also extract speakers' poses, facial expression, and vocal emotions. We then detect the changes in these modalities and visualize it by showing the video containing the timestamp.
## Run
'''streamlit run appTest.py'''
